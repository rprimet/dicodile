
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_gait.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_gait.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_gait.py:


Gait (steps) example
====================

In this example, we use DiCoDiLe on an open `dataset`_ of gait (steps)
IMU time-series to discover patterns in the data.
We will then use those to attempt to detect steps and compare our findings
with the ground truth.

.. _dataset: https://github.com/deepcharles/gait-data

.. GENERATED FROM PYTHON SOURCE LINES 12-22

.. code-block:: default


    import matplotlib.pyplot as plt
    import numpy as np

    from dicodile.data.gait import get_gait_data
    from dicodile.utils.dictionary import init_dictionary
    from dicodile.utils.viz import display_dictionaries
    from dicodile.utils.csc import reconstruct
    from dicodile import dicodile








.. GENERATED FROM PYTHON SOURCE LINES 23-25

Retrieve trial data
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 25-28

.. code-block:: default


    trial = get_gait_data(subject=6, trial=1)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading data from http://dev.ipol.im/~truong/GaitData.zip (192.3 MB)

    file_sizes:   0%|                                    | 0.00/202M [00:00<?, ?B/s]    file_sizes:   0%|                            | 24.6k/202M [00:00<21:01, 160kB/s]    file_sizes:   0%|                            | 49.2k/202M [00:00<21:05, 159kB/s]    file_sizes:   0%|                             | 106k/202M [00:00<13:07, 256kB/s]    file_sizes:   0%|                             | 221k/202M [00:00<07:29, 448kB/s]    file_sizes:   0%|                             | 451k/202M [00:00<04:04, 822kB/s]    file_sizes:   0%|1                           | 909k/202M [00:00<02:09, 1.55MB/s]    file_sizes:   1%|2                          | 1.83M/202M [00:01<01:07, 2.97MB/s]    file_sizes:   2%|4                          | 3.66M/202M [00:01<00:34, 5.78MB/s]    file_sizes:   4%|9                          | 7.33M/202M [00:01<00:17, 11.2MB/s]    file_sizes:   5%|#3                         | 9.95M/202M [00:01<00:14, 13.1MB/s]    file_sizes:   6%|#7                         | 13.1M/202M [00:01<00:12, 15.1MB/s]    file_sizes:   8%|##2                        | 16.8M/202M [00:01<00:10, 17.4MB/s]    file_sizes:   9%|##5                        | 18.9M/202M [00:02<00:11, 16.4MB/s]    file_sizes:  11%|###                        | 22.5M/202M [00:02<00:09, 18.3MB/s]    file_sizes:  12%|###3                       | 25.2M/202M [00:02<00:09, 17.9MB/s]    file_sizes:  14%|###7                       | 27.8M/202M [00:02<00:09, 17.7MB/s]    file_sizes:  15%|####                       | 30.4M/202M [00:02<00:09, 17.5MB/s]    file_sizes:  17%|####5                      | 34.1M/202M [00:02<00:08, 19.0MB/s]    file_sizes:  18%|####9                      | 36.7M/202M [00:02<00:08, 18.5MB/s]    file_sizes:  19%|#####2                     | 39.3M/202M [00:03<00:09, 18.0MB/s]    file_sizes:  21%|#####7                     | 43.0M/202M [00:03<00:08, 19.5MB/s]    file_sizes:  23%|######1                    | 45.6M/202M [00:03<00:08, 18.7MB/s]    file_sizes:  24%|######4                    | 48.2M/202M [00:03<00:08, 18.2MB/s]    file_sizes:  25%|######8                    | 50.8M/202M [00:03<00:08, 17.9MB/s]    file_sizes:  27%|#######2                   | 54.5M/202M [00:03<00:07, 19.3MB/s]    file_sizes:  28%|#######6                   | 57.1M/202M [00:04<00:07, 18.6MB/s]    file_sizes:  30%|########                   | 59.8M/202M [00:04<00:07, 18.1MB/s]    file_sizes:  31%|########4                  | 63.4M/202M [00:04<00:07, 19.4MB/s]    file_sizes:  33%|########8                  | 66.1M/202M [00:04<00:07, 18.7MB/s]    file_sizes:  34%|#########1                 | 68.7M/202M [00:04<00:07, 18.3MB/s]    file_sizes:  36%|#########6                 | 72.3M/202M [00:04<00:06, 19.6MB/s]    file_sizes:  37%|##########                 | 75.0M/202M [00:05<00:06, 18.9MB/s]    file_sizes:  38%|##########3                | 77.6M/202M [00:05<00:06, 18.3MB/s]    file_sizes:  40%|##########7                | 80.2M/202M [00:05<00:06, 18.0MB/s]    file_sizes:  42%|###########2               | 83.9M/202M [00:05<00:06, 19.3MB/s]    file_sizes:  43%|###########5               | 86.5M/202M [00:05<00:06, 18.7MB/s]    file_sizes:  44%|###########9               | 89.1M/202M [00:05<00:06, 18.0MB/s]    file_sizes:  46%|############4              | 92.8M/202M [00:05<00:05, 19.4MB/s]    file_sizes:  47%|############7              | 95.4M/202M [00:06<00:05, 18.9MB/s]    file_sizes:  49%|#############1             | 98.6M/202M [00:06<00:05, 19.1MB/s]    file_sizes:  51%|##############1             | 102M/202M [00:06<00:04, 20.1MB/s]    file_sizes:  52%|##############5             | 105M/202M [00:06<00:05, 19.3MB/s]    file_sizes:  53%|##############9             | 107M/202M [00:06<00:05, 18.5MB/s]    file_sizes:  55%|###############4            | 111M/202M [00:06<00:04, 19.8MB/s]    file_sizes:  56%|###############7            | 114M/202M [00:07<00:04, 19.0MB/s]    file_sizes:  58%|################1           | 116M/202M [00:07<00:04, 18.4MB/s]    file_sizes:  59%|################5           | 119M/202M [00:07<00:04, 18.0MB/s]    file_sizes:  61%|#################           | 123M/202M [00:07<00:04, 19.4MB/s]    file_sizes:  62%|#################3          | 125M/202M [00:07<00:04, 18.7MB/s]    file_sizes:  63%|#################7          | 128M/202M [00:07<00:04, 18.3MB/s]    file_sizes:  65%|##################1         | 131M/202M [00:07<00:03, 17.9MB/s]    file_sizes:  67%|##################6         | 134M/202M [00:08<00:03, 19.3MB/s]    file_sizes:  68%|##################9         | 137M/202M [00:08<00:03, 18.6MB/s]    file_sizes:  69%|###################3        | 139M/202M [00:08<00:03, 18.2MB/s]    file_sizes:  71%|###################8        | 143M/202M [00:08<00:02, 19.5MB/s]    file_sizes:  72%|####################1       | 145M/202M [00:08<00:03, 18.0MB/s]    file_sizes:  74%|####################6       | 149M/202M [00:08<00:02, 19.4MB/s]    file_sizes:  75%|####################9       | 151M/202M [00:09<00:02, 17.9MB/s]    file_sizes:  77%|#####################4      | 155M/202M [00:09<00:02, 19.3MB/s]    file_sizes:  78%|#####################7      | 157M/202M [00:09<00:02, 17.8MB/s]    file_sizes:  80%|######################2     | 160M/202M [00:09<00:02, 19.3MB/s]    file_sizes:  81%|######################7     | 164M/202M [00:09<00:01, 19.5MB/s]    file_sizes:  82%|#######################     | 166M/202M [00:09<00:01, 18.8MB/s]    file_sizes:  84%|#######################4    | 169M/202M [00:10<00:01, 18.3MB/s]    file_sizes:  86%|########################    | 174M/202M [00:10<00:01, 20.7MB/s]    file_sizes:  87%|########################3   | 176M/202M [00:10<00:01, 19.3MB/s]    file_sizes:  88%|########################6   | 178M/202M [00:10<00:01, 17.7MB/s]    file_sizes:  90%|#########################1  | 181M/202M [00:10<00:01, 19.1MB/s]    file_sizes:  91%|#########################5  | 184M/202M [00:10<00:00, 18.5MB/s]    file_sizes:  93%|#########################9  | 187M/202M [00:10<00:00, 18.1MB/s]    file_sizes:  94%|##########################4 | 190M/202M [00:11<00:00, 15.2MB/s]    file_sizes:  96%|##########################9 | 194M/202M [00:11<00:00, 13.7MB/s]    file_sizes:  98%|###########################3| 197M/202M [00:11<00:00, 15.0MB/s]    file_sizes:  99%|###########################6| 199M/202M [00:11<00:00, 14.7MB/s]    file_sizes: 100%|############################| 202M/202M [00:12<00:00, 15.0MB/s]    file_sizes: 100%|############################| 202M/202M [00:12<00:00, 16.7MB/s]
    Successfully downloaded file to /github/home/data/dicodile/gait/GaitData.zip




.. GENERATED FROM PYTHON SOURCE LINES 29-30

Let's have a look at the data for one trial.

.. GENERATED FROM PYTHON SOURCE LINES 30-33

.. code-block:: default


    trial.keys()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    dict_keys(['Subject', 'Trial', 'Code', 'Age', 'Gender', 'Height', 'Weight', 'BMI', 'Laterality', 'Sensor', 'WalkedDistance', 'WalkingSpeed', 'PathologyGroup', 'IsControl', 'LeftFootActivity', 'RightFootActivity', 'data'])



.. GENERATED FROM PYTHON SOURCE LINES 34-37

We get a dictionary whose keys are metadata items, plus a 'data' key that
contains a numpy array with the trial time series for each sensor axis,
at 100 Hz resolution.

.. GENERATED FROM PYTHON SOURCE LINES 37-41

.. code-block:: default


    # right foot acceleration (vertical)
    plt.plot(trial['data']['RAV'])




.. image:: /auto_examples/images/sphx_glr_plot_gait_001.png
    :alt: plot gait
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    [<matplotlib.lines.Line2D object at 0x7f7b55335940>]



.. GENERATED FROM PYTHON SOURCE LINES 42-44

Let's look at a small portion of the series for both feet,
overlaid on the same plot

.. GENERATED FROM PYTHON SOURCE LINES 44-54

.. code-block:: default


    fig, ax = plt.subplots()
    ax.plot(trial['data']['LAV'][5000:5800],
            label='left foot vertical acceleration')
    ax.plot(trial['data']['RAV'][5000:5800],
            label='right foot vertical acceleration')
    ax.set_xlabel('time (x10ms)')
    ax.set_ylabel('acceleration ($m.s^{-2}$)')
    ax.legend()




.. image:: /auto_examples/images/sphx_glr_plot_gait_002.png
    :alt: plot gait
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f7b55105fa0>



.. GENERATED FROM PYTHON SOURCE LINES 55-59

We can see the alternating left and right foot movements.

In the rest of this example, we will only use the right foot
vertical acceleration.

.. GENERATED FROM PYTHON SOURCE LINES 61-68

Convolutional Dictionary Learning
---------------------------------

Now, let's use DiCoDiLe to learn patterns from the data and reconstruct
the signal from a sparse representation.

First, we initialize a dictionary from parts of the signal:

.. GENERATED FROM PYTHON SOURCE LINES 68-76

.. code-block:: default


    X = trial['data']['RAV'].to_numpy()
    X = X.reshape(1, *X.shape)

    print(X.shape)

    D_init = init_dictionary(X, n_atoms=8, atom_support=(200,), random_state=60)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (1, 18639)




.. GENERATED FROM PYTHON SOURCE LINES 77-81

Note the use of ``reshape`` to shape the signal as per ``dicodile``
requirements: the shape of the signal should be
``(n_channels, *sig_support)``.
Here, we have a single-channel time series so it is ``(1, n_times)``.

.. GENERATED FROM PYTHON SOURCE LINES 83-84

Then, we run DiCoDiLe!

.. GENERATED FROM PYTHON SOURCE LINES 84-93

.. code-block:: default


    D_hat, z_hat, pobj, times = dicodile(
        X, D_init, n_iter=3, n_workers=4, window=True,
        dicod_kwargs={"max_iter": 10000}, verbose=6
    )


    print("[DiCoDiLe] final cost : {}".format(pobj))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [DEBUG:DICODILE] Lambda_max = 1.7133212673372127
    Started 4 workers in 2.27s
    [INFO:DICODILE] - CD iterations 0 / 3 (0s)
    [DEBUG:DICODILE] lambda = 1.713e-01
    [INFO:DICOD-4] converged in 1.739s (1.096s) with 26648 iterations (10055 updates).
    [DEBUG:DICODILE] Objective (z) : 1.446e+01 (2s)
    [INFO:Update D]: 4 iterations
    [DEBUG:DICODILE] Objective (d) : 1.403e+01  (1s)
    [INFO:DICODILE] - CD iterations 1 / 3 (3s)
    [DEBUG:DICODILE] lambda = 1.713e-01
    [INFO:DICOD-4] converged in 0.940s (0.623s) with 15850 iterations (4816 updates).
    [DEBUG:DICODILE] Objective (z) : 1.377e+01 (1s)
    [INFO:Update D]: 4 iterations
    [DEBUG:DICODILE] Objective (d) : 1.375e+01  (1s)
    [INFO:DICODILE] - CD iterations 2 / 3 (6s)
    [DEBUG:DICODILE] lambda = 1.713e-01
    [INFO:DICOD-4] converged in 0.960s (0.571s) with 17871 iterations (4875 updates).
    [DEBUG:DICODILE] Objective (z) : 1.359e+01 (1s)
    [INFO:Update D]: 3 iterations
    [DEBUG:DICODILE] Objective (d) : 1.356e+01  (1s)
    [INFO:DICOD-4] converged in 0.772s (0.489s) with 14118 iterations (3375 updates).
    [INFO:DICODILE] Finished in 8s
    [DiCoDiLe] final cost : [37.92317851302482, 14.463183032908248, 14.028260079808662, 13.770412091124935, 13.748544866374292, 13.594687831083338, 13.563401238391391, 13.487657052236582]




.. GENERATED FROM PYTHON SOURCE LINES 94-97

We can order the dictionary patches by decreasing sum of the activations'
absolute values in the activations ``z_hat``, which, intuitively, gives
a measure of how they contribute to the reconstruction.

.. GENERATED FROM PYTHON SOURCE LINES 97-106

.. code-block:: default


    sum_abs_val = np.sum(np.abs(z_hat), axis=-1)

    # we negate sum_abs_val to sort in decreasing order
    patch_indices = np.argsort(-sum_abs_val)

    fig_reordered = display_dictionaries(D_init[patch_indices],
                                         D_hat[patch_indices])




.. image:: /auto_examples/images/sphx_glr_plot_gait_003.png
    :alt: plot gait
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 107-111

Signal reconstruction
^^^^^^^^^^^^^^^^^^^^^

Now, let's reconstruct the original signal

.. GENERATED FROM PYTHON SOURCE LINES 111-114

.. code-block:: default


    X_hat = reconstruct(z_hat, D_hat)








.. GENERATED FROM PYTHON SOURCE LINES 115-116

Plot a small part of the original and reconstructed signals

.. GENERATED FROM PYTHON SOURCE LINES 116-126

.. code-block:: default


    fig_hat, ax_hat = plt.subplots()
    ax_hat.plot(X[0][5000:5800],
                label='right foot vertical acceleration (ORIGINAL)')
    ax_hat.plot(X_hat[0][5000:5800],
                label='right foot vertical acceleration (RECONSTRUCTED)')
    ax_hat.set_xlabel('time (x10ms)')
    ax_hat.set_ylabel('acceleration ($m.s^{-2}$)')
    ax_hat.legend()




.. image:: /auto_examples/images/sphx_glr_plot_gait_004.png
    :alt: plot gait
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f7b36051a90>



.. GENERATED FROM PYTHON SOURCE LINES 127-128

Check that our representation is indeed sparse:

.. GENERATED FROM PYTHON SOURCE LINES 128-131

.. code-block:: default


    np.count_nonzero(z_hat)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    592



.. GENERATED FROM PYTHON SOURCE LINES 132-134

Besides our visual check, a measure of how closely we're reconstructing the
original signal is the (normalized) cross-correlation. Let's compute this:

.. GENERATED FROM PYTHON SOURCE LINES 134-138

.. code-block:: default


    np.correlate(X[0], X_hat[0]) / (
        np.sqrt(np.correlate(X[0], X[0]) * np.correlate(X_hat[0], X_hat[0])))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    array([0.9763924])



.. GENERATED FROM PYTHON SOURCE LINES 139-145

Multichannel signals
--------------------

DiCoDiLe works just as well with multi-channel signals. The gait dataset
contains 16 signals (8 for each foot), in the rest of this tutorial,
we'll use three of those.

.. GENERATED FROM PYTHON SOURCE LINES 145-149

.. code-block:: default


    # Left foot Vertical acceleration, Y rotation and X acceleration
    channels = ['LAV', 'LRY', 'LAX']








.. GENERATED FROM PYTHON SOURCE LINES 150-151

Let's look at a small portion of multi-channel data

.. GENERATED FROM PYTHON SOURCE LINES 151-161

.. code-block:: default


    colors = plt.rcParams["axes.prop_cycle"]()
    mc_fig, mc_ax = plt.subplots(len(channels), sharex=True)

    for ax, chan in zip(mc_ax, channels):
        ax.plot(trial['data'][chan][5000:5800],
                label=chan, color=next(colors)["color"])
    mc_fig.legend(loc="upper center")





.. image:: /auto_examples/images/sphx_glr_plot_gait_005.png
    :alt: plot gait
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f7b35f590d0>



.. GENERATED FROM PYTHON SOURCE LINES 162-163

Let's put the data in shape for DiCoDiLe: (n_channels, n_times)

.. GENERATED FROM PYTHON SOURCE LINES 163-167

.. code-block:: default


    X_mc_subset = trial['data'][channels].to_numpy().T
    print(X_mc_subset.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (3, 18639)




.. GENERATED FROM PYTHON SOURCE LINES 168-170

Initialize the dictionary (note that the call is identical
to the single-channel version)

.. GENERATED FROM PYTHON SOURCE LINES 170-176

.. code-block:: default


    D_init_mc = init_dictionary(X_mc_subset,
                                n_atoms=8,
                                atom_support=(200,),
                                random_state=60)








.. GENERATED FROM PYTHON SOURCE LINES 177-179

And run DiCoDiLe (note that the call is identical to the single-channel
version here as well)

.. GENERATED FROM PYTHON SOURCE LINES 179-191

.. code-block:: default


    D_hat_mc, z_hat_mc, pobj_mc, times_mc = dicodile(X_mc_subset,
                                                     D_init_mc,
                                                     n_iter=3,
                                                     n_workers=4,
                                                     dicod_kwargs={"max_iter": 10000},  # noqa: E501
                                                     verbose=6,
                                                     window=True)


    print("[DiCoDiLe] final cost : {}".format(pobj_mc))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [DEBUG:DICODILE] Lambda_max = 903.7323963288766
    Started 4 workers in 2.37s
    [INFO:DICODILE] - CD iterations 0 / 3 (0s)
    [DEBUG:DICODILE] lambda = 9.037e+01
    [INFO:DICOD-4] converged in 2.066s (1.321s) with 32852 iterations (12144 updates).
    [DEBUG:DICODILE] Objective (z) : 5.744e+06 (2s)
    [PROGRESS:Update D] 1s -   3.00% iterations (1.587e-07)    [PROGRESS:Update D] 1s -   4.00% iterations (7.923e-08)    [INFO:Update D]: 5 iterations
    [DEBUG:DICODILE] Objective (d) : 5.553e+06  (2s)
    [INFO:DICODILE] - CD iterations 1 / 3 (5s)
    [DEBUG:DICODILE] lambda = 9.037e+01
    [INFO:DICOD-4] converged in 1.219s (0.785s) with 20778 iterations (6794 updates).
    [DEBUG:DICODILE] Objective (z) : 5.484e+06 (1s)
    [INFO:Update D]: 3 iterations
    [DEBUG:DICODILE] Objective (d) : 5.481e+06  (2s)
    [INFO:DICODILE] - CD iterations 2 / 3 (8s)
    [DEBUG:DICODILE] lambda = 9.037e+01
    [INFO:DICOD-4] converged in 0.711s (0.475s) with 10291 iterations (3874 updates).
    [DEBUG:DICODILE] Objective (z) : 5.470e+06 (1s)
    [INFO:Update D]: 2 iterations
    [DEBUG:DICODILE] Objective (d) : 5.469e+06  (2s)
    [INFO:DICOD-4] converged in 0.316s (0.151s) with 5017 iterations (1146 updates).
    [INFO:DICODILE] Finished in 10s
    [DiCoDiLe] final cost : [20304139.366815556, 5744062.502983235, 5553406.119739521, 5483929.073211681, 5481324.772065418, 5469548.633721547, 5469226.536386982, 5468370.8002749225]




.. GENERATED FROM PYTHON SOURCE LINES 192-196

Signal reconstruction (multichannel)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Now, let's reconstruct the original signal

.. GENERATED FROM PYTHON SOURCE LINES 196-200

.. code-block:: default


    X_hat_mc = reconstruct(z_hat_mc, D_hat_mc)
    X_hat_mc.shape





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (3, 18639)



.. GENERATED FROM PYTHON SOURCE LINES 201-203

Let's visually compare a small part of the original and reconstructed signals
along with the activations.

.. GENERATED FROM PYTHON SOURCE LINES 203-222

.. code-block:: default


    viz_start_idx = 4000
    viz_end_idx = 5800
    viz_chan = 2

    max_abs = np.max(np.abs(z_hat_mc), axis=-1)
    max_abs = max_abs.reshape(z_hat_mc.shape[0], 1)
    z_hat_normalized = z_hat_mc / max_abs
    fig_hat_mc, ax_hat_mc = plt.subplots(2, figsize=(12, 8))
    ax_hat_mc[0].plot(X_mc_subset[viz_chan][viz_start_idx:viz_end_idx],
                      label='ORIGINAL')
    ax_hat_mc[0].plot(X_hat_mc[viz_chan][viz_start_idx:viz_end_idx],
                      label='RECONSTRUCTED')
    for idx in range(z_hat_normalized.shape[0]):
        ax_hat_mc[1].stem(z_hat_normalized[idx][viz_start_idx:viz_end_idx],
                          linefmt=f"C{idx}-",
                          markerfmt=f"C{idx}o")
    ax_hat_mc[0].set_xlabel('time (x10ms)')
    ax_hat_mc[0].legend()



.. image:: /auto_examples/images/sphx_glr_plot_gait_006.png
    :alt: plot gait
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f7b33ded250>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  43.200 seconds)


.. _sphx_glr_download_auto_examples_plot_gait.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_gait.py <plot_gait.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_gait.ipynb <plot_gait.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
